{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from torchcontrib.optim import SWA\n",
    "import torchvision.models as models\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as albu\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import nvidia_smi\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scheduler import CosineAnnealingLR_with_Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(phase):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "        list_transforms.extend(\n",
    "            [\n",
    "                albu.HorizontalFlip(p=0.5)\n",
    "            ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            ToTensor()\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = albu.Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, phase):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase)\n",
    "        self.fnames = self.df.index.tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_id = self.df.iloc[idx].name\n",
    "        label = float(self.df.iloc[idx][:4].notnull().values.any()) \n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        augmented = self.transforms(image=img)\n",
    "        img = augmented['image']\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(SEED))\n",
    "    \n",
    "def provider(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    phase,\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    "):\n",
    "    '''Returns dataloader for the model training'''\n",
    "\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    image_dataset = SteelDataset(df, data_folder, phase)\n",
    "    dataloader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=False,\n",
    "        shuffle=True,   \n",
    "        worker_init_fn = _init_fn\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_log(phase, epoch, epoch_loss, start):\n",
    "    '''logging the metrics at the end of an epoch'''\n",
    "    \n",
    "    print(\"Loss: %0.4f\" % (epoch_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    def __init__(self, model, train_df, val_df, fold):\n",
    "          \n",
    "        self.lr = 5e-4\n",
    "        optimizer = SWA(optim.Adam(model.parameters(), lr=self.lr)) \n",
    "        \n",
    "        self.net, self.optimizer = amp.initialize(\n",
    "            model.to('cuda:0'), optimizer, opt_level=\"O2\", \n",
    "            keep_batchnorm_fp32=True, loss_scale=\"dynamic\")\n",
    "            \n",
    "        self.fold = fold\n",
    "        self.num_workers = 0\n",
    "        self.batch_size = {\"train\": 4, \"val\": 4}\n",
    "        self.accumulation_steps = 32 // self.batch_size['train']\n",
    "        self.num_epochs = 40\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.net = model\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.scheduler = CosineAnnealingLR_with_Restart(\n",
    "            self.optimizer,\n",
    "            T_max=6, \n",
    "            T_mult=1, \n",
    "            model=model, \n",
    "            out_dir=f'segmentation_fold_{fold}', \n",
    "            take_snapshot=True, \n",
    "            eta_min=1e-6)\n",
    "        self.net = self.net.to(self.device)\n",
    "        cudnn.benchmark = True\n",
    "        self.dataloaders = {\n",
    "            phase: provider(\n",
    "                train_df=train_df,\n",
    "                val_df=val_df,\n",
    "                phase=phase,\n",
    "                batch_size=self.batch_size[phase],\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        \n",
    "    def forward(self, images, targets):\n",
    "        images = images.to(self.device)\n",
    "        labels = targets.to(self.device).float()\n",
    "        outputs = self.net(images)\n",
    "        loss = self.criterion(torch.sigmoid(outputs), labels)\n",
    "        return loss, outputs\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        \n",
    "        start = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Starting epoch: {epoch} | phase: {phase} | ‚è∞: {start}\")\n",
    "        \n",
    "        batch_size = self.batch_size[phase]\n",
    "        self.net.train(phase == \"train\")\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(dataloader)\n",
    "        self.optimizer.zero_grad()\n",
    "    \n",
    "        for itr, batch in enumerate(dataloader):\n",
    "            images, targets = batch\n",
    "            loss, outputs = self.forward(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            if phase == \"train\":\n",
    "                with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                #loss.backward()\n",
    "                if (itr + 1 ) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            outputs = outputs.detach().cpu()\n",
    "\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches     \n",
    "        epoch_log(phase, epoch, epoch_loss, start)   \n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        \n",
    "        nvidia_smi.nvmlInit()\n",
    "        handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "        # card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "        res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n",
    "        print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return epoch_loss\n",
    "\n",
    "    def start(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.iterate(epoch, \"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.net.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "                'amp': amp.state_dict()\n",
    "            }\n",
    "            \n",
    "            #to prevent GPU memory from overflowing on validation\n",
    "            with torch.no_grad():\n",
    "                val_loss = self.iterate(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "                \n",
    "            if val_loss < self.best_loss:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_loss\"] = self.best_loss = val_loss\n",
    "                torch.save(state, f\"./model{self.fold}.pth\")\n",
    "            print()\n",
    "            if epoch > 10 and epoch % 4 == 0:\n",
    "                self.optimizer.update_swa()\n",
    "        self.optimizer.swap_swa_sgd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 69\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = './data/sample_submission.csv'\n",
    "train_df_path = './data/train.csv'\n",
    "data_folder = \"./data/\"\n",
    "test_data_folder = \"./data/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_df_path)\n",
    "df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "df['ClassId'] = df['ClassId'].astype(int)\n",
    "df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "df['defects'] = df.count(axis=1)\n",
    "df['defects'] = df['defects'].apply(lambda x : int(x >= 1))\n",
    "    \n",
    "train_df, validation_df = train_test_split(df, test_size=0.1, stratify=df[\"defects\"], random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "folds = 6\n",
    "\n",
    "kf = KFold(n_splits=folds, random_state=SEED, shuffle=True)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    model = models.resnext50_32x4d(classes=1)\n",
    "    model_trainer = Trainer(model, train_df.iloc[train_index], train_df.iloc[test_index], i+1)\n",
    "    model_trainer.start()\n",
    "    del(model_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationDataset(Dataset):\n",
    "    '''Dataset for test prediction'''\n",
    "    def __init__(self, root, df):\n",
    "        self.root = root\n",
    "        #df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "        self.fnames = df['ImageId'].unique().tolist()\n",
    "        self.num_samples = len(self.fnames)\n",
    "        self.transform = albu.Compose(\n",
    "            [\n",
    "                ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        path = os.path.join(self.root, fname)\n",
    "        image = cv2.imread(path)\n",
    "        images = self.transform(image=image)[\"image\"]\n",
    "        return fname, images\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "validation_df['ImageId'] = validation_df['defects'].keys()\n",
    "\n",
    "validationset = DataLoader(\n",
    "    ValidationDataset(f'{test_data_folder}/', validation_df),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "import operator\n",
    "\n",
    "checkpoints = []\n",
    "\n",
    "for fold in range(folds):\n",
    "    \n",
    "    out_dir = f'segmentation_fold_{fold+1}'\n",
    "    checkpoints = sorted(glob.glob(out_dir + '/*.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    model = resnet34(num_classes=1)\n",
    "    ch = torch.load(path, map_location={'cuda:0':'cpu'})\n",
    "    model.load_state_dict(ch['state_dict'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [load_model(ch) for ch in checkpoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(validationset, model):\n",
    "    predictions = []\n",
    "    device = torch.device(\"cuda\")\n",
    "    for i, batch in enumerate(tqdm(validationset)):\n",
    "        fnames, images = batch\n",
    "        batch_preds = torch.sigmoid(model(images.to(device)))\n",
    "        batch_preds = batch_preds.detach().cpu().numpy()\n",
    "        for fname, preds in zip(fnames, batch_preds):\n",
    "            for cls, pred in enumerate(preds):\n",
    "                predictions.append([fname, pred])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(preds, preds_class, true_labels):\n",
    "    f1_thresholds = {}\n",
    "    roc_auc_thresholds = {}\n",
    "    \n",
    "    ROC_AUC = roc_auc_score(true_labels, preds)\n",
    "    F1_score = f1_score(true_labels, preds_class)\n",
    "    \n",
    "    print(f'Default probability ROC AUC: {round(ROC_AUC, 3)}')\n",
    "    print(f'Default ROC AUC: {round(roc_auc_score(true_labels, preds_class), 3)}')\n",
    "    print(f'Default F1 score: {round(F1_score, 3)}')\n",
    "    print()\n",
    "    print('Confusion matrix: ')\n",
    "    print(confusion_matrix(true_labels, preds_class))\n",
    "    \n",
    "    # checking threshold \n",
    "    for thresh in np.arange(0.005, 0.95, 0.001): #change step to 0.01 \n",
    "        thresh = np.round(thresh, 2)\n",
    "        F1_score = f1_score(true_labels, (preds>thresh).astype(int))\n",
    "        ROC_AUC = roc_auc_score(true_labels, (preds>thresh).astype(int))\n",
    "        \n",
    "        f1_thresholds.update({thresh: F1_score})\n",
    "        roc_auc_thresholds.update({thresh: ROC_AUC})\n",
    "        \n",
    "    max_f1 = max(f1_thresholds.items(), key=operator.itemgetter(1))[1]\n",
    "    best_f1_thresh = max(f1_thresholds.items(), key=operator.itemgetter(1))[0]\n",
    "    \n",
    "    max_roc_auc = max(roc_auc_thresholds.items(), key=operator.itemgetter(1))[1]\n",
    "    best_roc_auc_thresh = max(roc_auc_thresholds.items(), key=operator.itemgetter(1))[0]\n",
    "    \n",
    "    best_preds_class = (preds>best_f1_thresh).astype(int)\n",
    "\n",
    "    print()\n",
    "    print(f'Best roc-auc score: {round(max_roc_auc, 3)} with threshold {best_roc_auc_thresh}')\n",
    "    print(f'Best f1 score: {round(max_f1, 3)} with threshold {best_f1_thresh}')\n",
    "       \n",
    "    print()\n",
    "    print('Updated Confusion Matrix: ')\n",
    "    print(confusion_matrix(true_labels, best_preds_class))\n",
    "    \n",
    "    return preds, best_preds_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(predictions): \n",
    "    df = pd.DataFrame(predictions, columns=['ImageId', 'Defected'])\n",
    "    df['Class'] = df['Defected'].apply(lambda x : int(x >= 0.85)) \n",
    "    model_results(df['Defected'].values, df['Class'].values, validation_df['defects'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (model) in enumerate(models):\n",
    "    print(F'Model: {i}')\n",
    "    \n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    predictions_df = predict(validationset, model)\n",
    "    \n",
    "    validate(predictions_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
