{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "import glob\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as albu\n",
    "from albumentations.torch import ToTensor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import nvidia_smi\n",
    "from apex import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SegmentationModel\n",
    "from scheduler import CosineAnnealingLR_with_Restart\n",
    "from losses import ComboLoss, compute_iou_batch, soft_bce_loss, soft_focal_loss, soft_dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLE-Mask utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 -> mask, 0 -> background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_mask(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name\n",
    "    labels = df.iloc[row_id][:4]\n",
    "    masks = np.zeros((256, 1600, 4), dtype=np.float32) # float32 is V.Imp\n",
    "    # 4:class 1～4 (ch:0～3)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * 1600, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n",
    "    return fname, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader + Augemation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(phase, mean, std):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "        list_transforms.extend(\n",
    "            [\n",
    "                albu.RandomBrightness(limit=(-0.25, 0.25), p=0.5),\n",
    "                albu.RandomContrast(limit=(-0.15, 0.4), p=0.5),\n",
    "                albu.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.5),\n",
    "                albu.HorizontalFlip(p=0.5)\n",
    "            ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            albu.Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = albu.Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, mean, std, phase):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase, mean, std)\n",
    "        self.fnames = self.df.index.tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id, mask = make_mask(idx, self.df)\n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = cv2.imread(image_path)\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask'] # 1x256x1600x4\n",
    "        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(SEED))\n",
    "\n",
    "def provider(\n",
    "    data_folder,\n",
    "    train_df,\n",
    "    valid_df,\n",
    "    phase,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    "):\n",
    "    '''Returns dataloader for the model training'''\n",
    "    \n",
    "    df = train_df if phase == \"train\" else valid_df\n",
    "    image_dataset = SteelDataset(df, data_folder, mean, std, phase)\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,       \n",
    "        worker_init_fn = _init_fn\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric scheduler + Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, threshold):\n",
    "    '''X is sigmoid output of the model'''\n",
    "    X_p = np.copy(X)\n",
    "    preds = (X_p > threshold).astype('uint8')\n",
    "    return preds\n",
    "\n",
    "class Meter:\n",
    "    '''A meter to keep track of iou and dice scores throughout an epoch'''\n",
    "    def __init__(self, phase, epoch):\n",
    "        self.base_threshold = 0.5\n",
    "        self.iou_scores = []\n",
    "        self.base_bce_scores = []\n",
    "        self.base_focal_scores = []\n",
    "        self.base_dice2_scores = []\n",
    "\n",
    "    def update(self, targets, outputs):\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        \n",
    "        preds = predict(probs, self.base_threshold)\n",
    "        iou = compute_iou_batch(preds, targets, classes=[1])\n",
    "        self.iou_scores.append(iou)\n",
    "        \n",
    "        bce = soft_bce_loss(probs, targets)\n",
    "        self.base_bce_scores.append(bce)\n",
    "        \n",
    "        focal = soft_focal_loss(probs, targets)\n",
    "        self.base_focal_scores.append(focal)\n",
    "        \n",
    "        dice2 = soft_dice_loss(probs, targets)\n",
    "        self.base_dice2_scores.append(dice2)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        #dice = np.mean(self.base_dice_scores)\n",
    "        #dice_neg = np.mean(self.dice_neg_scores)\n",
    "        #dice_pos = np.mean(self.dice_pos_scores)\n",
    "        #dices = [dice, dice_neg, dice_pos]\n",
    "    \n",
    "        iou = np.nanmean(self.iou_scores) \n",
    "        \n",
    "        bce = np.mean(self.base_bce_scores)\n",
    "        focal = np.mean(self.base_focal_scores)    \n",
    "        dice2 = np.mean(self.base_dice2_scores)\n",
    "        \n",
    "        return bce, focal, iou, dice2\n",
    "\n",
    "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
    "    '''logging the metrics at the end of an epoch'''\n",
    "    \n",
    "    bce, focal, iou, dice2 = meter.get_metrics()\n",
    "    \n",
    "    print(\"Loss: %0.4f | IoU: %0.4f | bce: %0.4f | focal: %0.4f | dice2: %0.4f\" % (epoch_loss, iou, bce, focal, dice2))\n",
    "    \n",
    "    return bce, focal, iou, dice2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    def __init__(self, model, train_df, valid_df, fold):\n",
    "         \n",
    "        self.lr = 5e-4\n",
    "        \n",
    "        optimizer = SWA(optim.Adam(model.parameters(), lr=self.lr))\n",
    "        \n",
    "        self.net, self.optimizer = amp.initialize(\n",
    "            model.to('cuda:0'), optimizer, opt_level=\"O2\",\n",
    "            keep_batchnorm_fp32=True, loss_scale=\"dynamic\")\n",
    "        \n",
    "        self.fold = fold\n",
    "        self.num_workers = 0\n",
    "        self.batch_size = {\"train\": 4, \"val\": 4}\n",
    "        self.accumulation_steps = 32 // self.batch_size['train']\n",
    "        self.num_epochs = 30\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.criterion = ComboLoss(weights={'bce':2, 'dice':2,'focal':1})\n",
    "        self.scheduler = CosineAnnealingLR_with_Restart(\n",
    "            self.optimizer,\n",
    "            T_max=6,\n",
    "            T_mult=1, \n",
    "            model=self.net, \n",
    "            out_dir='segmentation_fold_' + str(fold), \n",
    "            take_snapshot=True, \n",
    "            eta_min=1e-6)\n",
    "        self.net = self.net.to(self.device)\n",
    "        cudnn.benchmark = True\n",
    "        self.dataloaders = {\n",
    "            phase: provider(\n",
    "                data_folder=data_folder,\n",
    "                train_df=train_df,\n",
    "                valid_df=valid_df,\n",
    "                phase=phase,\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=self.batch_size[phase],\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.iou_scores = {phase: [] for phase in self.phases}\n",
    "        self.bce_scores = {phase: [] for phase in self.phases}\n",
    "        self.focal_scores = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        \n",
    "    def forward(self, images, targets):\n",
    "        images = images.to(self.device)\n",
    "        masks = targets.to(self.device)\n",
    "        outputs = self.net(images)\n",
    "        loss = self.criterion(outputs, masks)\n",
    "        return loss, outputs\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        meter = Meter(phase, epoch)\n",
    "        \n",
    "        start = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Starting epoch: {epoch} | phase: {phase} | ⏰: {start}\")\n",
    "        \n",
    "        batch_size = self.batch_size[phase]\n",
    "        self.net.train(phase == \"train\")\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(dataloader)\n",
    "        self.optimizer.zero_grad()\n",
    "    \n",
    "        for itr, batch in enumerate(dataloader):\n",
    "            images, targets = batch\n",
    "            loss, outputs = self.forward(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            if phase == \"train\":\n",
    "                with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                #loss.backward()\n",
    "                if (itr + 1 ) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            outputs = outputs.detach().cpu()\n",
    "            meter.update(targets, outputs)\n",
    "\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        \n",
    "        bce, focal, iou, dice = epoch_log(phase, epoch, epoch_loss, meter, start)   \n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.bce_scores[phase].append(bce)\n",
    "        self.focal_scores[phase].append(focal)\n",
    "        self.iou_scores[phase].append(iou)\n",
    "        self.dice_scores[phase].append(dice)\n",
    "        \n",
    "        nvidia_smi.nvmlInit()\n",
    "        handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "        # card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "        res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n",
    "        print(f'gpu: {res.gpu}%, gpu-mem: {res.memory}%')\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return epoch_loss\n",
    "\n",
    "    def start(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.iterate(epoch, \"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.net.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "                'amp': amp.state_dict()\n",
    "            }\n",
    "            \n",
    "            #to prevent GPU memory from overflowing on validation\n",
    "            with torch.no_grad():\n",
    "                val_loss = self.iterate(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "                \n",
    "            if val_loss < self.best_loss:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_loss\"] = self.best_loss = val_loss\n",
    "                torch.save(state, f'./model{self.fold}.pth' )\n",
    "                \n",
    "            if epoch % 9 == 0 or epoch > 9 and epoch % 3 == 0:\n",
    "                self.optimizer.update_swa()\n",
    "            print()\n",
    "        self.optimizer.swap_swa_sgd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 69\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = './data/sample_submission.csv'\n",
    "train_df_path = './data/train.csv'\n",
    "data_folder = \"./data/\"\n",
    "test_data_folder = \"./data/test_images\"\n",
    "traint_data_folder = './data/train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_df_path)\n",
    "\n",
    "df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "df['ClassId'] = df['ClassId'].astype(int)\n",
    "df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "df['defects'] = df.count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Starting epoch: 0 | phase: train | ⏰: 21:57:55\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-8f18be744fe9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSegmentationModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"efficientnet-b3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"imagenet\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel_trainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalidation_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmodel_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mmodel_trainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-e2c6e84039e4>\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             state = {\n\u001b[0;32m    111\u001b[0m                 \u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-e2c6e84039e4>\u001b[0m in \u001b[0;36miterate\u001b[1;34m(self, epoch, phase)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                     \u001b[0mscaled_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m                 \u001b[1;31m#loss.backward()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mitr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccumulation_steps\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\apex\\amp\\handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[1;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mloss_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_overflow_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_amp_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_amp_stash\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams_have_scaled_gradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\apex\\amp\\_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_with_master_weights\u001b[1;34m(self, scaler)\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mfp16_grads_needing_unscale_with_stash\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mpreexisting_fp32_grads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             preexisting_fp32_grads)\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;31m# fp32 params can be treated as they would be in the \"no_master_weights\" case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\apex\\amp\\scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed\u001b[1;34m(self, model_grads, stashed_master_grads, master_grads, scale_override)\u001b[0m\n\u001b[0;32m    182\u001b[0m                                              \u001b[0mmaster_grads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                                              \u001b[0mout_scale\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mgrads_have_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                                              out_scale/stashed_have_scale)\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;31m# Defer to update_scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\apex\\amp\\scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed_python\u001b[1;34m(self, model_grads, stashed_master_grads, master_grads, a, b)\u001b[0m\n\u001b[0;32m    146\u001b[0m                                                                  \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                                                                  \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                                                                  self.dynamic)\n\u001b[0m\u001b[0;32m    149\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python36\\lib\\site-packages\\apex\\amp\\scaler.py\u001b[0m in \u001b[0;36maxpby_check_overflow_python\u001b[1;34m(model_grad, stashed_grad, master_grad, a, b, check_overflow)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Exception handling for 18.04 compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_overflow\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mcpu_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mcpu_sum\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "for i, (train_index, validation_index) in enumerate(cv.split(df)):\n",
    "    model = SegmentationModel(\"efficientnet-b3\", encoder_weights=\"imagenet\", classes=4, activation='sigmoid')\n",
    "    model_trainer = Trainer(model, df.iloc[train_index], df.iloc[validation_index], i+1)\n",
    "    model_trainer.start()\n",
    "    del model_trainer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAINING\n",
    "losses = model_trainer.losses\n",
    "iou_scores = model_trainer.iou_scores\n",
    "bce_scores = model_trainer.bce_scores\n",
    "focal_scores = model_trainer.focal_scores\n",
    "dice_scores = model_trainer.dice_scores\n",
    "\n",
    "def plot(scores, name):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n",
    "    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n",
    "    plt.legend(); \n",
    "    plt.show()\n",
    "\n",
    "plot(losses, \"Combo loss\")\n",
    "plot(iou_scores, \"IoU score\")\n",
    "\n",
    "\n",
    "plot(bce_scores, \"BCE loss\")\n",
    "plot(dice_scores, \"Dice loss\")\n",
    "plot(focal_scores, \"Focal loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
